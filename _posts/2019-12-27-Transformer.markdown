---
layout: post
category: 深度学习模型
tags: [深度学习模型,Seq2Seq.注意力机制,Attention Model]
---

Transformer
===============


## 参考

[1] Attention Is All You Need [paper](https://arxiv.org/pdf/1706.03762.pdf)
[2] Transformer各层网络结构详解！[html](http://blog.itpub.net/69942346/viewspace-2658350/)
