---
layout: post
category: 深度学习模型
tags: [深度学习模型,Seq2Seq.注意力机制,Attention Model]
---

Seq2Seq (Sequence-to-sequence)
===============

## 概念

### Seq2Seq

> Seq2seq,是一种通用的编码器——解码器框架，可用于机器翻译、文本摘要、会话建模、图像字幕等场景中。包含两部分：Encoder和Decoder

![avatar](https://gwfp.github.io/static/images/19/07/29/seq2seqarchitectrue.png){:width='600px' height="200px"}

### Attention Model

> 注意力机制，

## RNN Encoder-Decoder




## 参考资料


[1] Dzmitry Bahdanau.Neural Machine Translation by jointly Learning to Align and Translate[J].ICLR,2015. 
[2] [Learning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078.pdf)

