---
layout: post
category: 数学基础
tags: [数学基础,线性代数]
---


线性代数 linear algebra
================

## 标量、向量、矩阵、张量

### 标量(scalar)

### 向量(vector)

### 矩阵(matrix)

### 张量(tensor)

## 转置(transpose)

## 矩阵和向量相乘

## 单位矩阵和逆矩阵

## 线性相关和生成子空间

## <a name='norm'>范数<a/>

### 范数的定义

> 范数norm：用来衡量向量大小的量,将向量映射到非负值的函数，即向量x的范数衡量原点到x的距离。	\\
范数的定义形式上是：	\\
$$
	L^{p}\sim \left \| x \right \|_{p}=(\sum_{i}\left | x_{i} \right |^{p})^\frac{1}{p},(p\in R,p\geqslant 1 )	(NORM-1)	\\
$$

> 范数的性质（范数是满足下列性质的任意函数）:	\\
1.f(x) = 0  =>  x = 0	\\
2.
$$
	f(x+y) \leqslant  f(x) + f(y)	\\
$$
3.
$$
	\forall \alpha \in R,f(\alpha x) = \left | \alpha  \right |f(x)	\\
$$

> p从无穷到0变化时，三维空间中到原点的距离（范数）为1的点构成的[图形的变化情况](https://blog.csdn.net/lz867422770/article/details/80013600)。
![avatar](https://gwfp.github.io/static/images/19/01/31/norm.png)

### \\(L^{2}\\) 范数

> 被成为欧几里得范数(Euclidean norm)公式(NORM-1)，当p=2时的L^2范数，表示从原点出发到向量x的欧几里得距离。因为使用非常频繁，经常简化为
$$
	\left \| x \right \|
$$
去掉了下标。

### 平方 \\(L^{2}\\) 范数

> 平方L^2范数也经常用来衡量向量大小，这时，向量的大小可以简单通过点积计算：
$$
	x^{T}\cdot x	\\
$$
（两个向量的点积可以用范数来表示
$$
	x^{T}y=\left \| x \right \|_{2}\left \| y \right \|_{2}cos\theta 
$$
其中\\(\theta\\)表示x和y之间的夹角）

平方L^2范数载数学和计算上上比L^2范数更方便，但在原点附近增长十分缓慢。在某些应用中，区分恰好时零的元素和非零但值很小的元素时，我们使用L^1范数。

### \\(L^{1}\\) 范数

> 简化为
$$
	\left \| x \right \|_{1} =\sum_{i}\left | x_{i} \right |
$$
经常作为非零元素数目的替代函数。

### \\(L^{\infty }\\) 范数

> 表示向量中具有最大幅值的元素的绝对值
$$
	\left \| x \right \|_{\infty }=\underset{a}{max}\left | x_{i} \right |
$$

### Frobenius范数(frobenius norm)

> 用来衡量矩阵的大小
$$
	\left \| A \right \|_{F}=\sqrt{\sum_{i_{i,j}}A_{i,j}^{2}}
$$
类似向量的\\(L^{2}\\)函数

## 特殊类型的矩阵和向量

### 对角矩阵(diagonal matrix)

### 对称(symmetric)

### 单位向量(unit vector)

> 具有单位<a href="norm">范数</a>(unit norm)的向量
$$
	\left \| x \right \|_{2} = 1
$$

### <a name='orthogonal-matrix'>正交矩阵(orthogonal matrix)</a>

> 正交(orthogonal)：如果
$$
	x^{T}y=0
$$
那么，向量x和向量y正交。

> 标准正交(orthonormal):

> 正交矩阵： 行向量和列向量是分别标准正交的方阵
$$
	A^{T}A=AA^{T}=I
$$
即
$$
	A^{-1}=A^{T}
$$

## 特征分解

> 将矩阵分解成一组特征向量和特征值 

## 奇异值分解

> 奇异值分解(single value decomposition, SVD),将矩阵分解为奇异向量(singular vector)和奇异值(single value)

## Moore-Penrose 伪逆

## 迹运算

## 行列式

> 记做det(A)

## 参考

[1]伊恩古德费洛.深度学习[M].北京:人民邮电出版社.2017:19-33
